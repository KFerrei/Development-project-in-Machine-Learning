{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b46ba610",
   "metadata": {},
   "source": [
    "# TAF MCE - UE Machine Learning\n",
    "## Project - Unit Test\n",
    "\n",
    "Authors: Kévin Ferreira, Emma Bonnem, Elias Tranchant\n",
    "Year: 2021-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f63c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70a49e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import project.py\n",
    "exec(open(\"./project.py\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a14309",
   "metadata": {},
   "source": [
    "# 1. Test import_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f633212e",
   "metadata": {},
   "source": [
    "We start by importing our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9139c59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance of Wavelet Transformed image</th>\n",
       "      <th>Skewness of Wavelet Transformed image</th>\n",
       "      <th>Curtosis of Wavelet Transformed image</th>\n",
       "      <th>Entropy of image</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Variance of Wavelet Transformed image  \\\n",
       "0                                   3.62160   \n",
       "1                                   4.54590   \n",
       "2                                   3.86600   \n",
       "3                                   3.45660   \n",
       "4                                   0.32924   \n",
       "...                                     ...   \n",
       "1367                                0.40614   \n",
       "1368                               -1.38870   \n",
       "1369                               -3.75030   \n",
       "1370                               -3.56370   \n",
       "1371                               -2.54190   \n",
       "\n",
       "      Skewness of Wavelet Transformed image  \\\n",
       "0                                   8.66610   \n",
       "1                                   8.16740   \n",
       "2                                  -2.63830   \n",
       "3                                   9.52280   \n",
       "4                                  -4.45520   \n",
       "...                                     ...   \n",
       "1367                                1.34920   \n",
       "1368                               -4.87730   \n",
       "1369                              -13.45860   \n",
       "1370                               -8.38270   \n",
       "1371                               -0.65804   \n",
       "\n",
       "      Curtosis of Wavelet Transformed image  Entropy of image  classification  \n",
       "0                                   -2.8073          -0.44699               0  \n",
       "1                                   -2.4586          -1.46210               0  \n",
       "2                                    1.9242           0.10645               0  \n",
       "3                                   -4.0112          -3.59440               0  \n",
       "4                                    4.5718          -0.98880               0  \n",
       "...                                     ...               ...             ...  \n",
       "1367                                -1.4501          -0.55949               1  \n",
       "1368                                 6.4774           0.34179               1  \n",
       "1369                                17.5932          -2.77710               1  \n",
       "1370                                12.3930          -1.28230               1  \n",
       "1371                                 2.6842           1.19520               1  \n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_banknote_authentication = import_dataset('data_banknote_authentication.txt', [\"Variance of Wavelet Transformed image\", \\\n",
    "                                                           \"Skewness of Wavelet Transformed image\", \\\n",
    "                                                           \"Curtosis of Wavelet Transformed image\", \\\n",
    "                                                           \"Entropy of image\", \"classification\"])\n",
    "data_banknote_authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901e63fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>7800</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>6700</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>7300</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>395</td>\n",
       "      <td>55.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>6700</td>\n",
       "      <td>4.9</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>notckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>396</td>\n",
       "      <td>42.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>7800</td>\n",
       "      <td>6.2</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>notckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>397</td>\n",
       "      <td>12.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>6600</td>\n",
       "      <td>5.4</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>notckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>398</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>7200</td>\n",
       "      <td>5.9</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>notckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>399</td>\n",
       "      <td>58.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>6800</td>\n",
       "      <td>6.1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>notckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   age    bp     sg   al   su     rbc        pc         pcc  \\\n",
       "0      0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent   \n",
       "1      1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent   \n",
       "2      2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent   \n",
       "3      3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present   \n",
       "4      4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent   \n",
       "..   ...   ...   ...    ...  ...  ...     ...       ...         ...   \n",
       "395  395  55.0  80.0  1.020  0.0  0.0  normal    normal  notpresent   \n",
       "396  396  42.0  70.0  1.025  0.0  0.0  normal    normal  notpresent   \n",
       "397  397  12.0  80.0  1.020  0.0  0.0  normal    normal  notpresent   \n",
       "398  398  17.0  60.0  1.025  0.0  0.0  normal    normal  notpresent   \n",
       "399  399  58.0  80.0  1.025  0.0  0.0  normal    normal  notpresent   \n",
       "\n",
       "             ba  ...  pcv    wc   rc  htn   dm  cad appet   pe  ane  \\\n",
       "0    notpresent  ...   44  7800  5.2  yes  yes   no  good   no   no   \n",
       "1    notpresent  ...   38  6000  NaN   no   no   no  good   no   no   \n",
       "2    notpresent  ...   31  7500  NaN   no  yes   no  poor   no  yes   \n",
       "3    notpresent  ...   32  6700  3.9  yes   no   no  poor  yes  yes   \n",
       "4    notpresent  ...   35  7300  4.6   no   no   no  good   no   no   \n",
       "..          ...  ...  ...   ...  ...  ...  ...  ...   ...  ...  ...   \n",
       "395  notpresent  ...   47  6700  4.9   no   no   no  good   no   no   \n",
       "396  notpresent  ...   54  7800  6.2   no   no   no  good   no   no   \n",
       "397  notpresent  ...   49  6600  5.4   no   no   no  good   no   no   \n",
       "398  notpresent  ...   51  7200  5.9   no   no   no  good   no   no   \n",
       "399  notpresent  ...   53  6800  6.1   no   no   no  good   no   no   \n",
       "\n",
       "    classification  \n",
       "0              ckd  \n",
       "1              ckd  \n",
       "2              ckd  \n",
       "3              ckd  \n",
       "4              ckd  \n",
       "..             ...  \n",
       "395         notckd  \n",
       "396         notckd  \n",
       "397         notckd  \n",
       "398         notckd  \n",
       "399         notckd  \n",
       "\n",
       "[400 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_kidney_disease = import_dataset('kidney_disease.csv')\n",
    "data_kidney_disease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84ea132",
   "metadata": {},
   "source": [
    "For the following parts, we will use the data_kidney_disease dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64851c22",
   "metadata": {},
   "source": [
    "# 2. replace_missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db508da",
   "metadata": {},
   "source": [
    "We replace the missing values and separate the decision data from the classification column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "995c7ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used_dataset = data_kidney_disease\n",
    "used_dataset = data_banknote_authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffcb9d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = replace_missing_values(used_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "673a07ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance of Wavelet Transformed image</th>\n",
       "      <th>Skewness of Wavelet Transformed image</th>\n",
       "      <th>Curtosis of Wavelet Transformed image</th>\n",
       "      <th>Entropy of image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Variance of Wavelet Transformed image  \\\n",
       "0                                   3.62160   \n",
       "1                                   4.54590   \n",
       "2                                   3.86600   \n",
       "3                                   3.45660   \n",
       "4                                   0.32924   \n",
       "...                                     ...   \n",
       "1367                                0.40614   \n",
       "1368                               -1.38870   \n",
       "1369                               -3.75030   \n",
       "1370                               -3.56370   \n",
       "1371                               -2.54190   \n",
       "\n",
       "      Skewness of Wavelet Transformed image  \\\n",
       "0                                   8.66610   \n",
       "1                                   8.16740   \n",
       "2                                  -2.63830   \n",
       "3                                   9.52280   \n",
       "4                                  -4.45520   \n",
       "...                                     ...   \n",
       "1367                                1.34920   \n",
       "1368                               -4.87730   \n",
       "1369                              -13.45860   \n",
       "1370                               -8.38270   \n",
       "1371                               -0.65804   \n",
       "\n",
       "      Curtosis of Wavelet Transformed image  Entropy of image  \n",
       "0                                   -2.8073          -0.44699  \n",
       "1                                   -2.4586          -1.46210  \n",
       "2                                    1.9242           0.10645  \n",
       "3                                   -4.0112          -3.59440  \n",
       "4                                    4.5718          -0.98880  \n",
       "...                                     ...               ...  \n",
       "1367                                -1.4501          -0.55949  \n",
       "1368                                 6.4774           0.34179  \n",
       "1369                                17.5932          -2.77710  \n",
       "1370                                12.3930          -1.28230  \n",
       "1371                                 2.6842           1.19520  \n",
       "\n",
       "[1372 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbe546ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1367    1\n",
       "1368    1\n",
       "1369    1\n",
       "1370    1\n",
       "1371    1\n",
       "Name: classification, Length: 1372, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f12f0ee",
   "metadata": {},
   "source": [
    "# 3. feature_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1629bb6",
   "metadata": {},
   "source": [
    "We select features based on their variance. If the variance of a column is below the defined value *var_thrs* then it is removed. We also make sure to get rid of the \"id\" column, useless for training and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b233a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_thrs = 0.05\n",
    "X_selected = feature_selection(var_thrs, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ec2c18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features before selection : 4\n",
      "Number of features after selection  : 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features before selection : {np.shape(X)[1]}\")\n",
    "print(f\"Number of features after selection  : {np.shape(X_selected)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48f1022f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699],\n",
       "       [  4.5459 ,   8.1674 ,  -2.4586 ,  -1.4621 ],\n",
       "       [  3.866  ,  -2.6383 ,   1.9242 ,   0.10645],\n",
       "       ...,\n",
       "       [ -3.7503 , -13.4586 ,  17.5932 ,  -2.7771 ],\n",
       "       [ -3.5637 ,  -8.3827 ,  12.393  ,  -1.2823 ],\n",
       "       [ -2.5419 ,  -0.65804,   2.6842 ,   1.1952 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee463044",
   "metadata": {},
   "source": [
    "# 4. center_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3932620",
   "metadata": {},
   "source": [
    "To get more accurate results, we make sure that the mean of each column is equal to 0 and the variance is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "700270f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalized = center_normalize(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a630d7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of normalized data : (1372, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of normalized data : {np.shape(X_normalized)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea952a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperance and variance for each column :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [-0.,  1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Esperance and variance for each column :\")\n",
    "np.around([(X_normalized[:,i].mean(), X_normalized[:,i].var())  for i in range(np.shape(X_normalized)[1])], decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48188e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.12180565,  1.14945512, -0.97597007,  0.35456135],\n",
       "       [ 1.44706568,  1.06445293, -0.89503626, -0.12876744],\n",
       "       [ 1.20780971, -0.77735215,  0.12221838,  0.61807317],\n",
       "       ...,\n",
       "       [-1.47235682, -2.62164576,  3.75901744, -0.75488418],\n",
       "       [-1.40669251, -1.75647104,  2.552043  , -0.04315848],\n",
       "       [-1.04712236, -0.43982168,  0.29861555,  1.1364645 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99b3d9f",
   "metadata": {},
   "source": [
    "# 5. split_training_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926a2a15",
   "metadata": {},
   "source": [
    "We then split the dataset into a training set and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d155737",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.5 # Percentage of the size of the training set over the whole data\n",
    "X_train, X_test, y_train, y_test = split_training_test(X_normalized, y,train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32efc954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the original data : (1372, 4)\n",
      "Shape of the training data : (686, 4)\n",
      "Shape of the testing data  : (686, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of the original data : {np.shape(X_normalized)}\")\n",
    "print(f\"Shape of the training data : {np.shape(X_train)}\")\n",
    "print(f\"Shape of the testing data  : {np.shape(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ac44eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the original class : (1372,)\n",
      "Shape of the training class : (686,)\n",
      "Shape of the testing class  : (686,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of the original class : {np.shape(y)}\")\n",
    "print(f\"Shape of the training class : {np.shape(y_train)}\")\n",
    "print(f\"Shape of the testing class  : {np.shape(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc55f15",
   "metadata": {},
   "source": [
    "# 6. cross_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c39e145",
   "metadata": {},
   "source": [
    "Next, we find the cross-validation score for each estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7cd265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_dict = {\n",
    "        \"Linear SVC\" : LinearSVC(),\n",
    "        \"Naive Bayes\" : GaussianNB(),\n",
    "        \"SGD Classifier\" : SGDClassifier(),\n",
    "        \"KNeighbors Classifier\" : KNeighborsClassifier(),\n",
    "        \"Random Forest\" : RandomForestClassifier()\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc118200",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_dict = {name : [] for name in estimators_dict.keys()}\n",
    "for esti_name in estimators_dict.keys() :\n",
    "    cross_dict[esti_name] = cross_validation(estimators_dict[esti_name], X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "529bdc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC :\n",
      "Cross-validation score : [0.97816594 0.98253275 0.99122807]\n",
      "\n",
      "=====================================================\n",
      "\n",
      "Naive Bayes :\n",
      "Cross-validation score : [0.83406114 0.79912664 0.84649123]\n",
      "\n",
      "=====================================================\n",
      "\n",
      "SGD Classifier :\n",
      "Cross-validation score : [0.95633188 0.98253275 0.98245614]\n",
      "\n",
      "=====================================================\n",
      "\n",
      "KNeighbors Classifier :\n",
      "Cross-validation score : [1. 1. 1.]\n",
      "\n",
      "=====================================================\n",
      "\n",
      "Random Forest :\n",
      "Cross-validation score : [0.99563319 0.97816594 0.99561404]\n",
      "\n",
      "=====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for estimator in cross_dict :\n",
    "    print(f\"{estimator} :\")\n",
    "    print(f\"Cross-validation score : {cross_dict[estimator]}\")\n",
    "    print(\"\\n=====================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd168a6",
   "metadata": {},
   "source": [
    "# 7 train_validate_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4466a6eb",
   "metadata": {},
   "source": [
    "Finally, we can train our model and output the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37ff159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_name = \"Linear SVC\"\n",
    "\n",
    "cross_val_score_value = cross_validation(estimators_dict[estimator_name], X_train, y_train)\n",
    "y_pred, model_accuracy_score, cm = train_validate_model(estimators_dict[estimator_name], X_train, y_train, X_test, y_test)\n",
    "ret_solo = {estimator_name: (y_pred, model_accuracy_score, cm, cross_val_score_value)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaf62866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear SVC': (array([1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "         0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "         1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "         1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "         0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "         1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "         1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "         0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "         1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "         1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "         1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "         1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "         0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "         0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "         1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "         1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "         0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "         1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "         1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "         0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "         0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "         1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "         1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "         1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "         1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 1, 0, 0], dtype=int64),\n",
       "  0.9854227405247813,\n",
       "  array([[363,   9],\n",
       "         [  1, 313]], dtype=int64),\n",
       "  array([0.97816594, 0.98253275, 0.99122807]))}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "060f5130",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {name : [] for name in estimators_dict.keys()}\n",
    "for esti_name in estimators_dict.keys() :\n",
    "    cross_val_score_value = cross_validation(estimators_dict[esti_name], X_train, y_train)\n",
    "    y_pred, model_accuracy_score, cm = train_validate_model(estimators_dict[esti_name], X_train, y_train, X_test, y_test)\n",
    "    results_dict[esti_name] = y_pred, model_accuracy_score, cm, cross_val_score_value\n",
    "ret_all =  results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cd92771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC :\n",
      "[1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0\n",
      " 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 1 0 0 0 1\n",
      " 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1\n",
      " 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 1 1 1 1 0\n",
      " 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1\n",
      " 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 1 1 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 1 1 0\n",
      " 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 1 1 0\n",
      " 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 1 0 0 1 1\n",
      " 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0\n",
      " 1 1 0 0 0 1 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1\n",
      " 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1\n",
      " 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1\n",
      " 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 1\n",
      " 1 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "Score of model accuracy : 0.9854227405247813\n",
      "Confusion matrix :\n",
      "[[363   9]\n",
      " [  1 313]]\n",
      "Cross-validation score : [0.97816594 0.98253275 0.99122807]\n",
      "\n",
      "=====================================================\n",
      "\n",
      "Naive Bayes :\n",
      "[0 1 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0\n",
      " 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 1 1 1\n",
      " 1 0 1 1 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 1\n",
      " 0 1 1 1 1 1 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 1 1 1 1 0\n",
      " 1 1 0 0 0 0 1 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1\n",
      " 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0\n",
      " 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1\n",
      " 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 0 1 1 0\n",
      " 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 1 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1\n",
      " 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0\n",
      " 0 0 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0\n",
      " 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 1 0 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 0\n",
      " 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0 0 1 0 1\n",
      " 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1\n",
      " 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 1 0 0 0 1\n",
      " 0 0 0 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 1 1\n",
      " 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0]\n",
      "Score of model accuracy : 0.826530612244898\n",
      "Confusion matrix :\n",
      "[[322  50]\n",
      " [ 56 258]]\n",
      "Cross-validation score : [0.83406114 0.79912664 0.84649123]\n",
      "\n",
      "=====================================================\n",
      "\n",
      "SGD Classifier :\n",
      "[1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0\n",
      " 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 0 1\n",
      " 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1\n",
      " 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 1 1 1 1 0\n",
      " 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 1 1\n",
      " 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 1 1 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 1 1 0\n",
      " 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 1 1 0\n",
      " 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 1 0 0 1 1\n",
      " 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1\n",
      " 0 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0\n",
      " 1 1 0 0 0 1 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1\n",
      " 0 1 0 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1\n",
      " 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1\n",
      " 0 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 1\n",
      " 1 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "Score of model accuracy : 0.9825072886297376\n",
      "Confusion matrix :\n",
      "[[361  11]\n",
      " [  1 313]]\n",
      "Cross-validation score : [0.97816594 0.98253275 0.99561404]\n",
      "\n",
      "=====================================================\n",
      "\n",
      "KNeighbors Classifier :\n",
      "[1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0\n",
      " 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 1\n",
      " 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 1 1 1 1 0\n",
      " 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1\n",
      " 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 1 1 0\n",
      " 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 1 1 0\n",
      " 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 1 0 0 1 1\n",
      " 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 0 1\n",
      " 1 1 0 0 0 1 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1\n",
      " 0 1 0 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1\n",
      " 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1\n",
      " 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 1\n",
      " 1 1 0 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "Score of model accuracy : 1.0\n",
      "Confusion matrix :\n",
      "[[370   2]\n",
      " [  0 314]]\n",
      "Cross-validation score : [1. 1. 1.]\n",
      "\n",
      "=====================================================\n",
      "\n",
      "Random Forest :\n",
      "[1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0\n",
      " 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 1\n",
      " 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 1 1 1 1 0\n",
      " 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1\n",
      " 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 1 1 0\n",
      " 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 1 1 0\n",
      " 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 1 0 0 1 1\n",
      " 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0\n",
      " 1 1 0 0 0 1 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1\n",
      " 0 1 0 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1\n",
      " 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1\n",
      " 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 1\n",
      " 1 1 0 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0]\n",
      "Score of model accuracy : 1.0\n",
      "Confusion matrix :\n",
      "[[369   3]\n",
      " [  2 312]]\n",
      "Cross-validation score : [0.99126638 0.97816594 0.99122807]\n",
      "\n",
      "=====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for estimator in results_dict :\n",
    "    print(f\"{estimator} :\")\n",
    "    print(results_dict[estimator][0])\n",
    "    print(f\"Score of model accuracy : {results_dict[estimator][1]}\")\n",
    "    print(f\"Confusion matrix :\\n{results_dict[estimator][2]}\")\n",
    "    print(f\"Cross-validation score : {results_dict[estimator][3]}\")\n",
    "    print(\"\\n=====================================================\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "216cc881fd7a9b3a54c6fb15327bf24b1328bb827d7e2cbeca3a18bdaa1d156c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
